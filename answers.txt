Reilly Hallstrom
Caleb Braun
05/11/2016

Question 1:

FIFO OS simulation with 1 CPU
# of Context Switches: 99
Total execution time: 67.6 s
Total time spent in READY state: 389.9 s

FIFO OS simulation with 2 CPU
# of Context Switches: 110
Total execution time: 35.9 s
Total time spent in READY state: 80.9 s


FIFO OS simulation with 4 CPU
# of Context Switches: 182
Total execution time: 33.4 s
Total time spent in READY state: 0.4 s

There is not a linear relationship between the number of CPUs and total execution time overall. When the CPU is running at maximum capacity, then doubling the number of processes would see a nearly linear speed-up.  When we run the simulation with one processor, the time spent in READY state is pretty high, indicating that processes spend a lot of time waiting for CPU time.  Therefore adding a second CPU caused it to be nearly twice as fast.  However, because two CPUs spend more time idling, adding even more does not cause the same linear speed-up.  In fact the speed-up between 2 CPUs and 4 is only a small percentage of the speed-up between 1 and 2.


Question 2:

RR OS simulation with 1 CPU with 800ms timeslice
# of Context Switches: 136
Total execution time: 67.6 s
Total time spent in READY state: 325.4 s

RR OS simulation with 1 CPU with 600ms timeslice
# of Context Switches: 161
Total execution time: 67.6 s
Total time spent in READY state: 314.5 s

RR OS simulation with 1 CPU with 400ms timeslice
# of Context Switches: 203
Total execution time: 67.6 s
Total time spent in READY state: 298.8 s

RR OS simulation with 1 CPU with 200ms timeslice
# of Context Switches: 362
Total execution time: 67.5 s
Total time spent in READY state: 285.2 s

The smaller timeslice we used did not affect the total execution time but did cause the total time spent in READY state to drop. As expected, the number of context switches increases because a process is more likely to be preempted during its given timeslice.  In a real OS, however, the shortest timeslice possible is not the best choice because we spend a higher amount of time context switching, and therefore less time with processes actually running.


Question 3:


FIFO has a waiting time of 389.9s
RR has an average waiting time of 300s
Static Priority has an average waiting time of 175s

According to our results Static Priority is the closest algorithm to Shortest Job First because Static Priority had a significantly shorter average wait time. This is because SJF is essentially a static priority scheduler with the priority being the estimated time remaining of a certain process whereas RR is similar to FIFO. In SJF the smaller the anticipated time remaining, the higher the priority. 




